{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1322c17f",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2340370859.py, line 156)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 156\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31m[cite_start]print(f\"\\nEnsemble Model MAPE: {mape_scores['Ensemble']:.2%}\") # [cite: 712]\u001b[39m\n                ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sns.set_style(\"whitegrid\")\n",
    "print(\"Libraries imported successfully.\")\n",
    "\n",
    "# --- Create output directory ---\n",
    "output_dir = \"outputs\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "print(f\"Output directory '{output_dir}' is ready.\")\n",
    "\n",
    "\n",
    "def create_lagged_features(data, window_size):\n",
    "    \"\"\"\n",
    "    Transforms a time series into a supervised learning dataset.\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - window_size):\n",
    "        X.append(data[i:i + window_size])\n",
    "        y.append(data[i + window_size])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "# 2. DATA LOADING AND PREPARATION\n",
    "file_names = [\n",
    "    'uber-raw-data-apr14.csv', 'uber-raw-data-may14.csv', 'uber-raw-data-jun14.csv',\n",
    "    'uber-raw-data-jul14.csv', 'uber-raw-data-aug14.csv', 'uber-raw-data-sep14.csv'\n",
    "]\n",
    "\n",
    "# Read and concatenate all files into a single dataframe\n",
    "try:\n",
    "    uber_2014 = pd.concat((pd.read_csv(f) for f in file_names), ignore_index=True)\n",
    "    print(f\"Successfully loaded and combined {len(file_names)} data files.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Make sure all 6 'uber-raw-data-...14.csv' files are in the same directory as the script.\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "uber_2014['Date/Time'] = pd.to_datetime(uber_2014['Date/Time'], format='%m/%d/%Y %H:%M:%S')\n",
    "\n",
    "# Set 'Date/Time' as the index\n",
    "uber_2014.set_index('Date/Time', inplace=True)\n",
    "uber_2014.sort_index(inplace=True)\n",
    "\n",
    "# Resample data into hourly trip counts, as done in the PDF\n",
    "hourly_counts = uber_2014['Base'].resample('h').count().reset_index()\n",
    "hourly_counts.columns = ['Date', 'Count'] # This line will now work correctly\n",
    "hourly_counts.set_index('Date', inplace=True)\n",
    "\n",
    "# --- Save prepared data ---\n",
    "hourly_counts.to_csv(os.path.join(output_dir, \"hourly_trip_counts.csv\"))\n",
    "print(f\"Prepared hourly data saved to '{output_dir}/hourly_trip_counts.csv'\")\n",
    "print(hourly_counts.head())\n",
    "\n",
    "\n",
    "# 3. EDA AND TRAIN/TEST SPLIT\n",
    "decomposition = seasonal_decompose(hourly_counts['Count'], model='additive', period=24)\n",
    "fig = decomposition.plot()\n",
    "fig.set_size_inches(14, 8)\n",
    "plt.suptitle(\"Time Series Decomposition of Hourly Uber Trips\", y=0.92)\n",
    "# --- Save plot ---\n",
    "plt.savefig(os.path.join(output_dir, \"time_series_decomposition.png\"), bbox_inches='tight')\n",
    "print(f\"Decomposition plot saved to '{output_dir}/time_series_decomposition.png'\")\n",
    "plt.show()\n",
    "\n",
    "cutoff_date = '2014-09-15 00:00:00'\n",
    "train_data = hourly_counts.loc[:cutoff_date]\n",
    "test_data = hourly_counts.loc[cutoff_date:]\n",
    "\n",
    "print(f\"Data split at {cutoff_date}. Training samples: {len(train_data)}, Testing samples: {len(test_data)}\")\n",
    "\n",
    "# Plotting the train/test split\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(train_data.index, train_data['Count'], label='Training Set')\n",
    "plt.plot(test_data.index, test_data['Count'], label='Test Set', color='orange')\n",
    "plt.title('Uber Trips: Train / Test Split')\n",
    "plt.ylabel('Number of Trips')\n",
    "plt.xlabel('Date')\n",
    "plt.legend()\n",
    "# --- Save plot ---\n",
    "plt.savefig(os.path.join(output_dir, \"train_test_split.png\"), bbox_inches='tight')\n",
    "print(f\"Train/Test split plot saved to '{output_dir}/train_test_split.png'\")\n",
    "plt.show()\n",
    "\n",
    "# 4. FEATURE ENGINEERING AND MODEL TRAINING\n",
    "window_size = 24\n",
    "X_train, y_train = create_lagged_features(train_data['Count'].values, window_size)\n",
    "test_features_base = np.concatenate([train_data['Count'].values[-window_size:], test_data['Count'].values])\n",
    "X_test, y_test = create_lagged_features(test_features_base, window_size)\n",
    "\n",
    "models = {\n",
    "    \"XGBoost\": xgb.XGBRegressor(\n",
    "        objective='reg:squarederror', colsample_bytree=1.0, learning_rate=0.1, max_depth=6,\n",
    "        n_estimators=300, subsample=0.6, random_state=12345\n",
    "    [cite_start]), # [cite: 486, 488]\n",
    "    \"Random Forest\": RandomForestRegressor(\n",
    "        n_estimators=100, max_depth=30, max_features=None, min_samples_leaf=2,\n",
    "        min_samples_split=5, random_state=12345\n",
    "    [cite_start]), # [cite: 556]\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(\n",
    "        n_estimators=300, learning_rate=0.1, max_depth=5, max_features='sqrt',\n",
    "        min_samples_leaf=1, min_samples_split=5, random_state=12345\n",
    "    [cite_start]) # [cite: 608]\n",
    "}\n",
    "\n",
    "predictions = {}\n",
    "mape_scores = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name} model...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    predictions[name] = preds\n",
    "    mape = mean_absolute_percentage_error(y_test, preds)\n",
    "    mape_scores[name] = mape\n",
    "    print(f\"{name} MAPE: {mape:.2%}\")\n",
    "\n",
    "# 5. ENSEMBLE MODEL AND FINAL EVALUATION\n",
    "weights = np.array([0.368, 0.322, 0.310])\n",
    "ensemble_preds = (\n",
    "    weights[0] * predictions['XGBoost'] +\n",
    "    weights[1] * predictions['Random Forest'] +\n",
    "    weights[2] * predictions['Gradient Boosting']\n",
    ")\n",
    "predictions['Ensemble'] = ensemble_preds\n",
    "mape_scores['Ensemble'] = mean_absolute_percentage_error(y_test, ensemble_preds)\n",
    "[cite_start]print(f\"\\nEnsemble Model MAPE: {mape_scores['Ensemble']:.2%}\") # [cite: 712]\n",
    "\n",
    "\n",
    "# --- Final Results Summary ---\n",
    "print(\"\\n--- Model Performance Summary ---\")\n",
    "summary_df = pd.DataFrame.from_dict(mape_scores, orient='index', columns=['MAPE'])\n",
    "summary_df['MAPE'] = summary_df['MAPE'].apply(lambda x: f\"{x:.2%}\")\n",
    "# --- Save summary data ---\n",
    "summary_df.sort_values('MAPE').to_csv(os.path.join(output_dir, \"model_performance_summary.csv\"))\n",
    "print(f\"Model performance summary saved to '{output_dir}/model_performance_summary.csv'\")\n",
    "print(summary_df.sort_values('MAPE'))\n",
    "\n",
    "# 6. VISUALIZATION OF ALL MODEL PREDICTIONS\n",
    "\n",
    "plt.figure(figsize=(18, 8))\n",
    "# Plot the actual test data\n",
    "plt.plot(test_data.index, test_data['Count'], label='Test (Actual Trips)', color='black', linewidth=2)\n",
    "\n",
    "# Plot model predictions\n",
    "colors = {'XGBoost': 'red', 'Random Forest': 'green', 'Gradient Boosting': 'orange', 'Ensemble': 'purple'}\n",
    "for name, preds in predictions.items():\n",
    "    plt.plot(test_data.index[window_size:], preds, label=f'{name} Predictions', linestyle='--', color=colors.get(name))\n",
    "\n",
    "plt.title('Uber 2014 Trips: All Models Predictions vs Test Data', fontsize=16)\n",
    "plt.ylabel('Number of Trips')\n",
    "plt.xlabel('Date')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=30, ha='right')\n",
    "# --- Save plot ---\n",
    "plt.savefig(os.path.join(output_dir, \"all_model_predictions.png\"), bbox_inches='tight')\n",
    "print(f\"Final predictions plot saved to '{output_dir}/all_model_predictions.png'\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f9e38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully.\n",
      "Output directory 'outputs' is ready.\n",
      "Error: Make sure all 6 'uber-raw-data-...14.csv' files are in the same directory as the script.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'uber_2014' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 54\u001b[39m\n\u001b[32m     51\u001b[39m     exit()\n\u001b[32m     53\u001b[39m \u001b[38;5;66;03m# Convert 'Date/Time' to datetime objects\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m uber_2014[\u001b[33m'\u001b[39m\u001b[33mDate/Time\u001b[39m\u001b[33m'\u001b[39m] = pd.to_datetime(\u001b[43muber_2014\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mDate/Time\u001b[39m\u001b[33m'\u001b[39m], \u001b[38;5;28mformat\u001b[39m=\u001b[33m'\u001b[39m\u001b[33m%\u001b[39m\u001b[33mm/\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m/\u001b[39m\u001b[33m%\u001b[39m\u001b[33mY \u001b[39m\u001b[33m%\u001b[39m\u001b[33mH:\u001b[39m\u001b[33m%\u001b[39m\u001b[33mM:\u001b[39m\u001b[33m%\u001b[39m\u001b[33mS\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# Set 'Date/Time' as the index\u001b[39;00m\n\u001b[32m     57\u001b[39m uber_2014.set_index(\u001b[33m'\u001b[39m\u001b[33mDate/Time\u001b[39m\u001b[33m'\u001b[39m, inplace=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mNameError\u001b[39m: name 'uber_2014' is not defined"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# 1. SETUP: IMPORT LIBRARIES AND DEFINE HELPER FUNCTIONS\n",
    "# ===================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sns.set_style(\"whitegrid\")\n",
    "print(\"Libraries imported successfully.\")\n",
    "\n",
    "# --- Create output directory ---\n",
    "output_dir = \"outputs\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "print(\"Output directory '{}' is ready.\".format(output_dir))\n",
    "\n",
    "# Helper function to create lagged features for time-series forecasting\n",
    "def create_lagged_features(data, window_size):\n",
    "    \"\"\"\n",
    "    Transforms a time series into a supervised learning dataset.\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - window_size):\n",
    "        X.append(data[i:i + window_size])\n",
    "        y.append(data[i + window_size])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "# ===================================================================\n",
    "# 2. DATA LOADING AND PREPARATION\n",
    "# ===================================================================\n",
    "# List of the 2014 data files mentioned in the PDF\n",
    "file_names = [\n",
    "    'uber-raw-data-apr14.csv', 'uber-raw-data-may14.csv', 'uber-raw-data-jun14.csv',\n",
    "    'uber-raw-data-jul14.csv', 'uber-raw-data-aug14.csv', 'uber-raw-data-sep14.csv'\n",
    "]\n",
    "\n",
    "# Read and concatenate all files into a single dataframe\n",
    "try:\n",
    "    uber_2014 = pd.concat((pd.read_csv(f) for f in file_names), ignore_index=True)\n",
    "    print(\"Successfully loaded and combined {} data files.\".format(len(file_names)))\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Make sure all 6 'uber-raw-data-...14.csv' files are in the same directory as the script.\")\n",
    "    exit()\n",
    "\n",
    "# Convert 'Date/Time' to datetime objects\n",
    "uber_2014['Date/Time'] = pd.to_datetime(uber_2014['Date/Time'], format='%m/%d/%Y %H:%M:%S')\n",
    "\n",
    "# Set 'Date/Time' as the index\n",
    "uber_2014.set_index('Date/Time', inplace=True)\n",
    "uber_2014.sort_index(inplace=True)\n",
    "\n",
    "# Resample data into hourly trip counts\n",
    "hourly_counts = uber_2014['Base'].resample('h').count().reset_index()\n",
    "hourly_counts.columns = ['Date', 'Count']\n",
    "hourly_counts.set_index('Date', inplace=True)\n",
    "\n",
    "# --- Save prepared data ---\n",
    "hourly_counts.to_csv(os.path.join(output_dir, \"hourly_trip_counts.csv\"))\n",
    "print(\"Prepared hourly data saved to '{}/hourly_trip_counts.csv'\".format(output_dir))\n",
    "print(hourly_counts.head())\n",
    "\n",
    "\n",
    "# ===================================================================\n",
    "# 3. EDA AND TRAIN/TEST SPLIT\n",
    "# ===================================================================\n",
    "# Perform seasonal decomposition\n",
    "decomposition = seasonal_decompose(hourly_counts['Count'], model='additive', period=24)\n",
    "fig = decomposition.plot()\n",
    "fig.set_size_inches(14, 8)\n",
    "plt.suptitle(\"Time Series Decomposition of Hourly Uber Trips\", y=0.92)\n",
    "plt.savefig(os.path.join(output_dir, \"time_series_decomposition.png\"), bbox_inches='tight')\n",
    "print(\"Decomposition plot saved to '{}/time_series_decomposition.png'\".format(output_dir))\n",
    "plt.show()\n",
    "\n",
    "# Split data\n",
    "cutoff_date = '2014-09-15 00:00:00'\n",
    "train_data = hourly_counts.loc[:cutoff_date]\n",
    "test_data = hourly_counts.loc[cutoff_date:]\n",
    "\n",
    "print(\"Data split at {}. Training samples: {}, Testing samples: {}\".format(cutoff_date, len(train_data), len(test_data)))\n",
    "\n",
    "# Plotting the train/test split\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(train_data.index, train_data['Count'], label='Training Set')\n",
    "plt.plot(test_data.index, test_data['Count'], label='Test Set', color='orange')\n",
    "plt.title('Uber Trips: Train / Test Split')\n",
    "plt.ylabel('Number of Trips')\n",
    "plt.xlabel('Date')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(output_dir, \"train_test_split.png\"), bbox_inches='tight')\n",
    "print(\"Train/Test split plot saved to '{}/train_test_split.png'\".format(output_dir))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ===================================================================\n",
    "# 4. FEATURE ENGINEERING AND MODEL TRAINING\n",
    "# ===================================================================\n",
    "window_size = 24\n",
    "X_train, y_train = create_lagged_features(train_data['Count'].values, window_size)\n",
    "test_features_base = np.concatenate([train_data['Count'].values[-window_size:], test_data['Count'].values])\n",
    "X_test, y_test = create_lagged_features(test_features_base, window_size)\n",
    "\n",
    "models = {\n",
    "    \"XGBoost\": xgb.XGBRegressor(\n",
    "        objective='reg:squarederror', colsample_bytree=1.0, learning_rate=0.1, max_depth=6,\n",
    "        n_estimators=300, subsample=0.6, random_state=12345\n",
    "    ),\n",
    "    \"Random Forest\": RandomForestRegressor(\n",
    "        n_estimators=100, max_depth=30, max_features=None, min_samples_leaf=2,\n",
    "        min_samples_split=5, random_state=12345\n",
    "    ),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(\n",
    "        n_estimators=300, learning_rate=0.1, max_depth=5, max_features='sqrt',\n",
    "        min_samples_leaf=1, min_samples_split=5, random_state=12345\n",
    "    )\n",
    "}\n",
    "\n",
    "predictions = {}\n",
    "mape_scores = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(\"\\nTraining {} model...\".format(name))\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    predictions[name] = preds\n",
    "    mape = mean_absolute_percentage_error(y_test, preds)\n",
    "    mape_scores[name] = mape\n",
    "    print(\"{} MAPE: {:.2%}\".format(name, mape))\n",
    "\n",
    "\n",
    "# ===================================================================\n",
    "# 5. ENSEMBLE MODEL AND FINAL EVALUATION\n",
    "# ===================================================================\n",
    "weights = np.array([0.368, 0.322, 0.310])\n",
    "ensemble_preds = (\n",
    "    weights[0] * predictions['XGBoost'] +\n",
    "    weights[1] * predictions['Random Forest'] +\n",
    "    weights[2] * predictions['Gradient Boosting']\n",
    ")\n",
    "predictions['Ensemble'] = ensemble_preds\n",
    "mape_scores['Ensemble'] = mean_absolute_percentage_error(y_test, ensemble_preds)\n",
    "print(\"\\nEnsemble Model MAPE: {:.2%}\".format(mape_scores['Ensemble']))\n",
    "\n",
    "\n",
    "# --- Final Results Summary ---\n",
    "print(\"\\n--- Model Performance Summary ---\")\n",
    "summary_df = pd.DataFrame.from_dict(mape_scores, orient='index', columns=['MAPE'])\n",
    "summary_df['MAPE'] = summary_df['MAPE'].apply(lambda x: \"{:.2%}\".format(x))\n",
    "summary_df.sort_values('MAPE').to_csv(os.path.join(output_dir, \"model_performance_summary.csv\"))\n",
    "print(\"Model performance summary saved to '{}/model_performance_summary.csv'\".format(output_dir))\n",
    "print(summary_df.sort_values('MAPE'))\n",
    "\n",
    "\n",
    "# ===================================================================\n",
    "# 6. VISUALIZATION OF ALL MODEL PREDICTIONS\n",
    "# ===================================================================\n",
    "plt.figure(figsize=(18, 8))\n",
    "plt.plot(test_data.index, test_data['Count'], label='Test (Actual Trips)', color='black', linewidth=2)\n",
    "\n",
    "colors = {'XGBoost': 'red', 'Random Forest': 'green', 'Gradient Boosting': 'orange', 'Ensemble': 'purple'}\n",
    "for name, preds in predictions.items():\n",
    "    plt.plot(test_data.index[window_size:], preds, label='{} Predictions'.format(name), linestyle='--', color=colors.get(name))\n",
    "\n",
    "plt.title('Uber 2014 Trips: All Models Predictions vs Test Data', fontsize=16)\n",
    "plt.ylabel('Number of Trips')\n",
    "plt.xlabel('Date')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=30, ha='right')\n",
    "plt.savefig(os.path.join(output_dir, \"all_model_predictions.png\"), bbox_inches='tight')\n",
    "print(\"Final predictions plot saved to '{}/all_model_predictions.png'\".format(output_dir))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
